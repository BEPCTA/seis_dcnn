{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import os, glob, datetime as dt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from helpers import *\n",
    "import random\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "lr = 0.005\n",
    "batch_size = 32\n",
    "n_train_data = 1000 * batch_size # use all available training data\n",
    "data_dir = 'data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, n_layers = 17, n_channels=64, image_channels = 1, use_bnorm = True, kernel_size = 3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, \n",
    "                                kernel_size=kernel_size, padding=padding, bias=True))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(n_layers - 2):\n",
    "            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, \n",
    "                                    kernel_size=kernel_size, padding=padding, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, \n",
    "                                kernel_size=kernel_size, padding=padding, bias=False))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dncnn(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                \n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "        print('weights initialized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLastCheckpoint(save_dir):\n",
    "    file_list = glob.glob(\"./saved_models/model_*.pth\")\n",
    "    if file_list:\n",
    "        epochs_exist = []\n",
    "        for file_ in file_list:\n",
    "            result = re.findall(\".*model_(.*).pth.*\", file_)\n",
    "            epochs_exist.append(int(result[0]))\n",
    "        initial_epoch = max(epochs_exist)\n",
    "    else:\n",
    "        initial_epoch = 0\n",
    "    return initial_epoch\n",
    "\n",
    "def log(e, l, t, r = 1):\n",
    "    out = \"epoch = {:2d}, loss = {:8.2f}, time = {:4d} seconds, rate = {:1.1f}\".\\\n",
    "    format(e, l, round(t.total_seconds()), r )\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S   \"), out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DnCNN()\n",
    "    \n",
    "initial_epoch = findLastCheckpoint(save_dir=save_dir)\n",
    "if initial_epoch > 1:\n",
    "    print('resuming from epoch %03d\\n' % (initial_epoch-1))\n",
    "  \n",
    "    if initial_epoch >= n_epoch:\n",
    "        print(\"done\")\n",
    "    else:\n",
    "        model = torch.load(os.path.join(save_dir, 'model_%03d.pth' % (initial_epoch-1)))\n",
    "model.train()\n",
    "criterion = nn.MSELoss()\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[20, 30, 40], gamma=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/landmass1\"\n",
    "patch_size = 99\n",
    "from helpers import read_matlab\n",
    "xs = read_matlab(data_dir, patch_size, n_train_data)\n",
    "print(xs.shape)\n",
    "xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))\n",
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(initial_epoch, n_epoch):\n",
    "    r = random.sample([0.6, 0.7, 0.8, 2,3,4,5],1)[0]\n",
    "    DDataset = DownsampleDataset(xs, r) \n",
    "    DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "    epoch_loss = 0\n",
    "    start_time = dt.datetime.now()\n",
    "\n",
    "    for n_count, batch_yx in enumerate(DLoader):\n",
    "            optimizer.zero_grad()\n",
    "            batch_x = batch_yx[1].cuda()\n",
    "            batch_y = batch_yx[0].cuda()\n",
    "            loss = criterion(model(batch_y), batch_x)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    scheduler.step(epoch)\n",
    "    elapsed_time = dt.datetime.now() - start_time\n",
    "    log(epoch+1, epoch_loss, elapsed_time, r) \n",
    "    torch.save(model, \"saved_models/model_{:03d}.pth\".format(epoch+1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfpytorch] *",
   "language": "python",
   "name": "conda-env-tfpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
